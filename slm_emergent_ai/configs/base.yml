# 基本設定ファイル - SLM Emergent AIの基本設定
# システムの基本設定を定義するYAMLファイル。

# SLM Emergent AI 基本設定
model:
  path: "C:\\Users\\admin\\Desktop\\slm\\SIM_MurmurNet\\scripts\\models\\gemma-3-1b-it-q4_0.gguf"  # ローカルGGUFモデルパス
  quantize: "q4"     # 量子化レベル (Note: may not apply directly to HF transformers loading)
  n_ctx: 2048        # コンテキスト長を2048に増加（元: 512）
  # boids_logits_params: # BoidsLogitsProcessor parameters moved under model
    # enabled: true    # Enable Boids for GGUF (experimental)
    # w_align: 0.05                # Alignment weight (reduced from 0.1)
    # w_sep: 0.3                   # Separation weight (increased from 0.2)
    # w_cohesion: 0.1              # Cohesion weight (reduced from 0.15)
    # n_align_tokens: 15           # Number of recent tokens for alignment vector
    # m_sep_tokens: 15           # Number of recent tokens for separation check
    # theta_sep: 0.80              # Separation similarity threshold (reduced from 0.85)
    # # Example of a general cohesion prompt text.
    # # If not provided or empty, run_sim.py will use the first initial_prompt.
    # cohesion_prompt_text: "Focus on collaborative problem solving, shared understanding, and innovative ideas."

agent:
  n: 3               # エージェント数
  max_turns: 10      # 最大ターン数
  roles:             # エージェントの役割
    - "Agent"        # Simplified to a single, generic role

# Note: The 'lambda' section below is for an older/alternative Boids mechanism or other system.
# It's separate from boids_logits_params used by BoidsLogitsProcessor and likely obsolete.
lambda:
  a: 0.3             # 整列ルールの重み
  c: 0.3             # 結合ルールの重み
  s: 0.1             # 分離ルールの重み

memory:
  mode: "local"      # メモリモード (local or distributed)
  redis_url: null    # Redis URL (分散モード時のみ)

controller:
  target_H: 5.0      # 目標エントロピー
  Kp: 0.1            # 比例ゲイン
  Ki: 0.01           # 積分ゲイン
  Kd: 0.05           # 微分ゲイン

metrics:
  port: 7861         # メトリクスサーバーポート (If used)

ui:
  enabled: true      # UIの有効化
  port: 7860         # UIポート

rag:
  enabled: false     # RAGの有効化
  backend: "chroma"  # バックエンド (chroma or elastic)
  config:
    persist_directory: "./chroma_db"  # ChromaDBの永続化ディレクトリ

runtime:
  threads: 6         # スレッド数 (Mainly for GGUF if not using HF)
  device: "cpu"      # Device for model and processing ('cpu', 'cuda', 'mps', etc.)

evaluation:
  enabled: true      # 評価指標の有効化
  freq: 3            # 評価頻度（ステップごと）

prompts:
  initial:           # 初期プロンプト for agents
    - "You are an AI agent. Your current task is to contribute to a collaborative discussion. Consider the ongoing conversation and the overall goals. Offer insightful questions, constructive solutions, or critical analysis as appropriate to move the discussion forward in a helpful manner."
    - "As an AI agent, your objective is to engage in a productive dialogue. Analyze the information available, build upon previous points, and help explore the topic comprehensively. Provide clear, concise, and relevant contributions."
    - "You are part of a team of AI agents working together. Your role is to facilitate a dynamic and emergent discussion. Think critically, be creative, and ensure your input is valuable to the collective task. Aim for novel insights or helpful elaborations."
