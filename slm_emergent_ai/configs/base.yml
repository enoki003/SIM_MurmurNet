# 基本設定ファイル - SLM Emergent AIの基本設定
# システムの基本設定を定義するYAMLファイル。

# SLM Emergent AI 基本設定
model:
  path: "C:/Users/admin/Desktop/slm/SIM_MurmurNet/scripts/models/gemma-3-1b-it-q4_0.gguf"  # モデルパス
  quantize: "q4"     # 量子化レベル (q4, q8, etc.)
  n_ctx: 4096        # コンテキスト長（トークン数）

agent:
  n: 3               # エージェント数
  max_turns: 10      # 最大ターン数
  roles:             # エージェントの役割
    - "質問者"
    - "回答者"
    - "批評者"

lambda:
  a: 0.3             # 整列ルールの重み
  c: 0.3             # 結合ルールの重み
  s: 0.1             # 分離ルールの重み

memory:
  mode: "local"      # メモリモード (local or distributed)
  redis_url: null    # Redis URL (分散モード時のみ)

controller:
  target_H: 5.0      # 目標エントロピー
  Kp: 0.1            # 比例ゲイン
  Ki: 0.01           # 積分ゲイン
  Kd: 0.05           # 微分ゲイン

metrics:
  port: 7861         # メトリクスサーバーポート

ui:
  enabled: true      # UIの有効化
  port: 7860         # UIポート

rag:
  enabled: false     # RAGの有効化
  backend: "chroma"  # バックエンド (chroma or elastic)
  config:
    persist_directory: "./chroma_db"  # ChromaDBの永続化ディレクトリ

runtime:
  threads: 6         # スレッド数

evaluation:
  enabled: true      # 評価指標の有効化
  freq: 3            # 評価頻度（ステップごと）

prompts:
  initial:           # 初期プロンプト
    - "あなたは質問者です。"
    - "あなたは回答者です"
    - "あなたは批判者です"
